{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d09fdb",
   "metadata": {},
   "source": [
    "# South African Language Identification Hack 2022\n",
    "### EDSA 2201 & 2207 classification hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abbdf",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Import necessary libraries</a>\n",
    "\n",
    "<a href=#two>2. Load and view the data</a>\n",
    "\n",
    "<a href=#three>3. Data Preprocessing</a>\n",
    "\n",
    "<a href=#four>4. Splitting the data</a>\n",
    "\n",
    "<a href=#five>5. Performance Metrics for model evaluation</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262727b",
   "metadata": {},
   "source": [
    "###  Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1aa67",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "From South African Government"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb323b0",
   "metadata": {},
   "source": [
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97460afb",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b77977",
   "metadata": {},
   "source": [
    "The dataset used for this challenge is the NCHLT Text Corpora collected by the South African Department of Arts and Culture & Centre for Text Technology (CTexT, North-West University, South Africa). The training set was improved through additional cleaning done by Praekelt.\n",
    "\n",
    "The data is in the form Language ID, Text. The text is in various states of cleanliness. Some NLP techniques will be necessary to clean up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef0ecd",
   "metadata": {},
   "source": [
    "### 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d046d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999420b",
   "metadata": {},
   "source": [
    "### 2. Load and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b0306ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "test = pd.read_csv(\"test_set.csv\")\n",
    "train = pd.read_csv(\"train_set.csv\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604be6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7c89bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f34658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056ade",
   "metadata": {},
   "source": [
    "The data is in the form Language ID, Text. The text is in various states of cleanliness. Some NLP techniques will be necessary to clean up the data.. A description of each variable in the dataset is given below.  \n",
    "### Training set\n",
    "**Variable definitions:**  \n",
    "\n",
    "- **lang_id** - Unique Language ID.\n",
    "- **Text** -  string characters.       \n",
    "  \n",
    "\n",
    "**Each text is then labeled as one of the following languages:**  \n",
    " \n",
    "    \n",
    "| **Class** | **Tag** |\n",
    "|:---------:|:---------\n",
    "|   **2**   | **tsn** |\n",
    "|   **1**   | **nbi** |\n",
    " \n",
    "\n",
    "### Testing set  \n",
    "During testing we do not have access to the **lang_id\t** variable, but the testing dataset remains the same as the training dataset otherwise.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c16f3",
   "metadata": {},
   "source": [
    "### Data types \n",
    "\n",
    "Let's get quick overview of the datasets we will be working with throughout the notebook. The output below contains the shape of the dataset, a list of all columns with their data types and the number of non-null values present in each column.  \n",
    "\n",
    "**Train data**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07da2132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a096f6f",
   "metadata": {},
   "source": [
    "The train dataset has 33000 entries, contains no null entries, and the data types for \"lang_id\" and \"text\" are both object data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf10354",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8416d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8268a",
   "metadata": {},
   "source": [
    "The test dataset has 5682 entries, contains no null entries, and the variable \"tesxt\" has the object data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cac2fd",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e13a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   lang_id  33000 non-null  bool \n",
      " 1   text     33000 non-null  bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 64.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "#Identifying missing values and data types\n",
    "train.isna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50711805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   index   5682 non-null   bool \n",
      " 1   text    5682 non-null   bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 11.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.isna().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41310a9e",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7472b345",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'axes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-17948f65ff07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'axes' is not defined"
     ]
    }
   ],
   "source": [
    "sns.countplot(train.lang_id, ax=axes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bbfaf",
   "metadata": {},
   "source": [
    "Looking at the above graph, there seems to be no class **imbalance**, therefore**:**\n",
    "* **No** need for **upsampling** and,\n",
    "* **No** need for **downsampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1566b6",
   "metadata": {},
   "source": [
    "#### Copying train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08aa6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lang = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de107a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_extract(text):  \n",
    "    \n",
    "  \n",
    "    hashtags = []\n",
    "\n",
    "    for a in text:\n",
    "        ht = re.findall(r\"#(\\w+)\", a)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    hashtags = sum(hashtags, [])\n",
    "    frequency = nltk.FreqDist(hashtags)\n",
    "\n",
    "    hashtag_data = pd.DataFrame({'hashtag': list(frequency.keys()),\n",
    "                           'count': list(frequency.values())})\n",
    "    hashtag_data = hashtag_data.nlargest(15, columns=\"count\")\n",
    "\n",
    "    return hashtag_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc0aba",
   "metadata": {},
   "source": [
    "#### Replacing url's and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021153c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all url/websites\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+' #url regualr expressions\n",
    "subs_url = r'url-web' # replace each url with 'url-web'\n",
    "data_lang['text'] = data_lang['text'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "# make all lower case \n",
    "data_lang['text'] = data_lang['text'].str.lower()\n",
    "\n",
    "#Removing RT ftom tweets\n",
    "data_lang['text'] = data_lang['text'].str.strip('rt ')\n",
    "\n",
    "# Remove @ mentions\n",
    "pattern = r\"@[\\w]+\" # pattern to remove\n",
    "sub = r'' # what to replace it with\n",
    "data_lang['text'] = data_lang['text'].replace(to_replace = pattern, value = sub, regex = True) #replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ddb026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_dict(text, dictionary):\n",
    "    \n",
    "    for word in text.split(): \n",
    "        if word.lower() in dictionary: \n",
    "            if word.lower() in text.split():\n",
    "                text = text.replace(word, dictionary[word.lower()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20581851",
   "metadata": {},
   "source": [
    "#### Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d269912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>he province of kwazulunatal department of tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1         xho  idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2         eng  he province of kwazulunatal department of tran...\n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "...       ...                                                ...\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove puntuation\n",
    "data_lang['text'] = data_lang['text'].apply(lambda x: ''.join([l for l in x if l not in string.punctuation]))\n",
    "data_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44112bb1",
   "metadata": {},
   "source": [
    "#### Tokentizing  the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e5487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the tweets\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "data_lang['tokenized'] = data_lang['text'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2946edb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "      <td>[umgaqosiseko, wenza, amalungiselelo, kumaziko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "      <td>[idha, iya, kuba, nobulumko, bokubeka, umseben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>he province of kwazulunatal department of tran...</td>\n",
       "      <td>[he, province, of, kwazulunatal, department, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqosiseko wenza amalungiselelo kumaziko axh...   \n",
       "1     xho  idha iya kuba nobulumko bokubeka umsebenzi nap...   \n",
       "2     eng  he province of kwazulunatal department of tran...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [umgaqosiseko, wenza, amalungiselelo, kumaziko...  \n",
       "1  [idha, iya, kuba, nobulumko, bokubeka, umseben...  \n",
       "2  [he, province, of, kwazulunatal, department, o...  \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...  \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac06040",
   "metadata": {},
   "source": [
    "### 4. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "578fb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting features and target variables\n",
    "X = train['text']#X is the features of the cleaned tweets\n",
    "y = train['lang_id'] #Y is the target variable which is the train sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0358bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer() #Call the TFidfVectorizer\n",
    "cf= CountVectorizer() #Call the CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa40907",
   "metadata": {},
   "source": [
    "#### Training model and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425da90f",
   "metadata": {},
   "source": [
    "### 5. Performance Metrics for model evaluation\n",
    "\n",
    "We will evaluate our models using the the F1 Score which is the number of true instances for each label.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} $$\n",
    "\n",
    "#### Recall\n",
    "\n",
    "The recall is intuitively the ability of the classifier to find all the positive samples\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}$$\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "Weighted average of precision and recall. \n",
    "\n",
    "$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b477e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9954545454545455\n",
      "f1_score 0.9954522748128464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       323\n",
      "         eng       1.00      1.00      1.00       280\n",
      "         nbl       0.98      0.99      0.98       295\n",
      "         nso       1.00      1.00      1.00       316\n",
      "         sot       1.00      1.00      1.00       307\n",
      "         ssw       0.99      1.00      0.99       295\n",
      "         tsn       1.00      1.00      1.00       296\n",
      "         tso       1.00      1.00      1.00       297\n",
      "         ven       1.00      1.00      1.00       258\n",
      "         xho       0.99      1.00      0.99       317\n",
      "         zul       0.99      0.98      0.98       316\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_r = LogisticRegression(C=1, class_weight='balanced', max_iter=1000)\n",
    "# call the model\n",
    "clf_lr = Pipeline([('tfidf', tfidf), ('clf', l_r)]) #Create a pipeline\n",
    "clf_lr.fit(X_train, y_train) #Fit the training data to the pipeline\n",
    "y_pred_lr= clf_lr.predict(X_test)#Make predictions\n",
    "print('accuracy %s' % accuracy_score(y_pred_lr, y_test)) #Print the accuracy\n",
    "print('f1_score %s' % metrics.f1_score(y_test,y_pred_lr,average='weighted')) #Print the weighted f1 score\n",
    "print(classification_report(y_test, y_pred_lr)) #Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8894c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9981818181818182\n",
      "f1_score 0.99818151138554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       323\n",
      "         eng       0.99      1.00      1.00       280\n",
      "         nbl       0.99      1.00      0.99       295\n",
      "         nso       1.00      1.00      1.00       316\n",
      "         sot       1.00      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       295\n",
      "         tsn       1.00      1.00      1.00       296\n",
      "         tso       1.00      1.00      1.00       297\n",
      "         ven       1.00      1.00      1.00       258\n",
      "         xho       1.00      1.00      1.00       317\n",
      "         zul       1.00      0.99      1.00       316\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_b = MultinomialNB()\n",
    "clf_nb= Pipeline([('tfidf', tfidf), ('clf', n_b)])\n",
    "clf_nb.fit(X_train, y_train)\n",
    "y_pred_nb = clf_nb.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred_nb, y_test)) #Print the accuracy\n",
    "print('f1_score %s' % metrics.f1_score(y_test,y_pred_nb,average='weighted')) #Print the f1 score\n",
    "print(classification_report(y_test, y_pred_nb)) #Print out the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c82f3e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB Hyperparameter tuning\n",
    "tfid = TfidfVectorizer()\n",
    "text = tfid.fit_transform(train['text'])\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(text,y, test_size = 0.2, random_state = 10)\n",
    "params = {'alpha':[0.01,0.1,1]}\n",
    "\n",
    "grid_MNB = GridSearchCV(MultinomialNB(), params)\n",
    "grid_MNB.fit(X_train_h, y_train_h)\n",
    "print(grid_MNB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2598dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9981818181818182\n",
      "f1_score 0.99818151138554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       323\n",
      "         eng       0.99      1.00      1.00       280\n",
      "         nbl       0.99      1.00      0.99       295\n",
      "         nso       1.00      1.00      1.00       316\n",
      "         sot       1.00      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       295\n",
      "         tsn       1.00      1.00      1.00       296\n",
      "         tso       1.00      1.00      1.00       297\n",
      "         ven       1.00      1.00      1.00       258\n",
      "         xho       1.00      1.00      1.00       317\n",
      "         zul       1.00      0.99      1.00       316\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi = Pipeline([('tfid', TfidfVectorizer()),\n",
    "             ('clf', MultinomialNB(alpha = 0.1))])\n",
    "multi.fit(X_train, y_train)\n",
    "t = test['text']\n",
    "y_pred_m = multi.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_m })\n",
    "sub.to_csv('submission_m.csv', index = False)\n",
    "print('accuracy %s' % accuracy_score(y_pred_nb, y_test)) #Print the accuracy\n",
    "print('f1_score %s' % metrics.f1_score(y_test,y_pred_nb,average='weighted')) #Print the f1 score\n",
    "print(classification_report(y_test, y_pred_nb)) #Print out the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a59ef71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Submission\n",
    "My_submission = pd.DataFrame(test['index'])\n",
    "My_submission['lang_id'] = clf_nb.predict(test['text'])\n",
    "My_submission.to_csv('Tebelelo_Selowa_Classification_Hackathon',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426134f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
